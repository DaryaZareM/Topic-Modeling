{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging Chat models\n",
    "\n",
    "![](https://huggingface.co/front/assets/huggingface_logo-noborder.svg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hugchat import hugchat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "def q_metrics(y_true, y_pred,my_model=None):\n",
    "    contigency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    purity = np.sum(np.amax(contigency_matrix, axis=0)) / np.sum(contigency_matrix)\n",
    "  \n",
    "    print('purity_score:',purity)\n",
    "    print('NMI:',metrics.normalized_mutual_info_score(y_true, y_pred))\n",
    "    \n",
    "    if my_model!=None:\n",
    "        cm = CoherenceModel(model=my_model, corpus=bow_corpus, dictionary=dictionary, coherence='u_mass')\n",
    "        print('Coherence:',cm.get_coherence())\n",
    "\n",
    "def print_result(resres,my_model=None):\n",
    "    pred = []\n",
    "    for i in range(len(resres)):\n",
    "        pred.append(np.argmax(resres[i]))\n",
    "  \n",
    "    y_true = df[df['div']=='test']['topic']\n",
    "    y_pred = pred\n",
    "    q_metrics(y_true, y_pred,my_model)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = hugchat.ChatBot(cookie_path=\"cookies.json\")  # or cookies=[...]\n",
    "\n",
    "# Create a new conversation\n",
    "id = chatbot.new_conversation()\n",
    "chatbot.change_conversation(id)\n",
    "\n",
    "# Get conversation list\n",
    "conversation_list = chatbot.get_conversation_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"”Economics” Economics is a social science that studies the production, distribution, and consumption of goods and services. Economics focuses on the behaviour and interactions of economic agents and how economies work.\n",
    "\n",
    "I will ask you to classify a tweet as of the topics described below:\n",
    "\n",
    "- stock, text is about stock,\n",
    "- currency, texts that are about price foreign currencies like dollar(except Toman and Rial), gold, oil, cryptocurrency.\n",
    "- commodities, texts that are about price of a commoditie like price of house, price of car,  price of airplain ticket,  price of water, price of gass or ...  (except gold and oil)don't care who said, context is important for us.\n",
    "- other, texts that are about other things that are not commodities for example politic desicions, budget, banking, insurance, poverty or ... .\n",
    "\n",
    "\n",
    "Now, which of\n",
    "- stock\n",
    "- currency\n",
    "- commodities\n",
    "- other\n",
    "topics best fit the following tweet? Answer with only the previous options that is most accurate and nothing else. Just name one of them with no more explanation.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "q='''Economic: aim to analyze and understand the allocation of resources, the behavior of markets, and the impact of economic decisions on individuals and society as a whole.\n",
    "\n",
    "I will ask you to classify a tweet as of the topics described below:\n",
    "\n",
    "- CURRENCY: If tweet is about foreign currencies like dollar(except Toman and Rial), gold,golden coin, oil or crypto currency and currency Exchange.\n",
    "- STOCK: If tweet is about stock market news and price and stock Exchange and shares.\n",
    "- COMMODITIES: If tweet is not about currency or stock and say something about a commodity like price of house,decrease in price of car,sell of airplain ticket, water, gas or ... (other than gold and oil).\n",
    "- NOT-COMMODITIES: If tweet is not about currency or stock and a commodity for example politic desicions, budget, banking, insurance, poverty or ... .\n",
    "\n",
    "Now, which of\n",
    "- CURRENCY\n",
    "- STOCK\n",
    "- COMMODITIES\n",
    "- NOT-COMMODITIES\n",
    "topics best fit the following tweet? Answer with only the previous options that is most accurate and nothing else. Just name one of them with no more explanation.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "q='''\n",
    "Economic: aim to analyze and understand the allocation of resources, the behavior of markets, and the impact of economic decisions on individuals and society as a whole.\n",
    "\n",
    "I will ask you to classify a tweet as of the topics described below:\n",
    "\n",
    "- CURRENCY: If tweet is about foreign currencies like dollar(except Toman and Rial), gold, oil, crypto currency and currency Exchange.\n",
    "- STOCK: If tweet is about stock market news, price, stock exchange and shares.\n",
    "- COMMODITIES: If tweet is not about currency or stock and say something about a commodity like price of house,decrease in price of car,sell of airplain ticket, water, gas or ... (other than gold and oil).\n",
    "- NOT-COMMODITIES: If tweet is not about currency or stock and a commodity for example politic decisions, budget, banking, insurance, poverty or ... .\n",
    "\n",
    "Now, which of CURRENCY, STOCK, COMMODITIES and NOT-COMMODITIES topics best fit the following tweet? Answer with only the previous options that is most accurate and nothing else. Just name one of them with no more explanation.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''\n",
    "this is a text about economics.\n",
    "tag it, If tweet is about foreign currencies like dollar(except Toman and Rial), gold, oil, crypto currency and currency Exchange tag as <CURRENCY>\n",
    "If tweet is about stock market news, price, stock exchange and shares tag as <STOCK> \n",
    "if it is about price of a commodities like price of house, price of car,  price of arplain ticket,  price of water, price of gass or ...  (other than gold and oil)don't care who sed, context is important for us tag as <COMMODITIES>\n",
    "If tweet is not about currency or stock and a commodity for example politic decisions, budget, banking, insurance, poverty or ... . tag as <NOT-COMMODITIES>\n",
    "output is only one word <stok> or <currency> or <commodities> or <NOT-COMMODITIES>\n",
    "\n",
    "Text:\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''\n",
    "this is a text about economics.\n",
    "tag it whith description on bellow,\n",
    "\n",
    "\n",
    " If the tweet is about stock market news, price, stock exchange, and shares.\n",
    "         tag = <STOCK>\n",
    " else:\n",
    "  If the text is about currencies(not price of a commodity) like dollar(except iranians like tomans and rial), gold, oil, cryptocurrency, and currency Exchange.\n",
    "        tag = <CURRENCY>\n",
    " else:\n",
    "  if no commodities were related and refers to abstracts. for example political decisions, budget, banking, insurance, poverty, and ...\n",
    "        tag = <NOT-COMMODITIES>\n",
    " else:\n",
    "  if the text refers to a commodity.\n",
    "        tag = <COMMODITIES>\n",
    " \n",
    "output is only one word <STOCK> or <CURRENCY> or <COMMODITIES> or <NOT-COMMODITIES>\n",
    "\n",
    "\n",
    "Text:\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "q= '''Please classify the following text into one of the insurance topics described below:\n",
    "Insurance: an arrangement where a company or the state provides compensation for specific loss, damage, illness, or death in exchange for a premium payment.\n",
    "\n",
    "<Third-party>: insurance that covers damages or losses caused by the policyholder to a third party, but not to the policyholder themselves. It's often mandatory for certain types of insurance, like car insurance, and is generally less expensive than comprehensive coverage. In Iran, Third-party insurance for cars is mandatory, and when people don't specify which type of insurance they have for their car, it means they have Third-party insurance.\n",
    "<Health>: insurance taken out to cover the cost of medical care, such as doctor and hospital costs, and the cost of medicine.\n",
    "<Social-Security>: different kinds of insurance programs, such as Social Security organization, Life insurance, Unemployment Insurance, and retirement insurance.\n",
    "<Other>\n",
    "The text is about insurance in Iran and asks you to identify the category that best fits a tweet. Please choose one of the options above: <Insurance>, <Third-party>, <Health>, <Social-Security>, or <Other>. Provide only one word without any explanation.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the openai library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data labels: Counter({'tamin': 31, 'insurance': 29, 'health': 20, 'person': 17})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nb/d3bw47gn6qj6n_bg2n_g5y140000gn/T/ipykernel_2047/2667410368.py:3: DtypeWarning: Columns (61,64,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_labeled = pd.read_csv(f'{path}insurance_dataset.csv')\n"
     ]
    }
   ],
   "source": [
    "df_labeled = pd.read_csv(f'{path}insurance_dataset.csv')\n",
    "df_labeled = df_labeled[df_labeled['div']=='test'].reset_index(drop=True)\n",
    "\n",
    "print('Test data labels:',Counter(df_labeled.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'این متن فارسی درباره کدام یک از موضوعات زیر است؟'\n",
    "topics=' economics , sport , art , health , social , politics'\n",
    "output_format='\\n\\noutput format is a json file like: \\n{\"Topic\": <<choosed topic>>}'\n",
    "# output_format='\\n\\noutput format is a json like: \\n{\"Category\": <<choosed category>>}'\n",
    "output_format='\\n\\noutput format is only one word:\\nTopic: <<choosed topic>>}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_trans= 'step1: read the Text then translate it from fa to en\\n step2: tag it, if text is about movie, teater, television, actors and actress or other jobs about making movie or teater tag as <film>\\nif text is a poem from a persian poet then tag as <poet> if text is about other arts expect poem or movia like book, cloth, fasion, game or ... tag as <art>'\n",
    "\n",
    "q_g_trans= ' tag this text, if text is about movie teater television actors and actress or other jobs about making movie or teater tag as <film>\\nif text is a poem from a persian poet then tag as <poet> if text is about other arts expect poem or movia like book, cloth, fasion, game or ... tag as <art>'\n",
    "output = '\\noutput is only one word <film> or <poet> or <art> then explain why'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "q= 'this is a persian text. read the Text and tag it, if text is about price of dollar, gold, oil, crypto currency tag as <currency>\\nif text is about stock then tag as <stock> if text is about a price of a commodity, goods,things(other than gold and oil) or tickets tag as <good> if text is about other things that are not commodity for example politic desicions or budget or banking or insurance or poverty or ... tag as <other>'\n",
    "\n",
    "q_trans= 'step1: read the Text then translate it from fa to en\\n step2: tag it, if text is about price of dollar, gold, oil, crypto currency tag as <currency>\\nif text is about stock then tag as <stock> if text is about price of a thing (other than gold and oil) tag as <thing> if text is about other things that are not commodity for example politic desicions or budget or banking or insurance or poverty or ... tag as <other>'\n",
    "\n",
    "q_g_trans= 'this is a text about economics. tag it, if text is about price of dollar, gold, oil, crypto currency tag as <currency>\\nif text is about stock then tag as <stock> if text is about price of a thing (other than gold and oil) tag as <thing> if text is about other things that are not commodity for example politic desicions or budget or banking or insurance or poverty or ... tag as <other>'\n",
    "output = '\\noutput is only one word <stok> or <currency> or <thing> or <other>'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q = '''this text is about insurance in  Iran.\n",
    "The text is about which of these topics?\n",
    "\n",
    "-<Third-party>: Third-party insurance is a type of insurance It is often mandatory for certain types of insurance, like car insurance, and is generally less expensive than comprehensive coverage. In Iran we are forced to get Third-party insurance for cars, and if we say insurance for cars without specification means Third-party insurance.\n",
    "-<Health>: Health insurance taken out to cover the cost of medical care, doctor costs, medicine, hospital and ….\n",
    "- <Social-Security>: Social-Security that is about Social Security organisation and also Life insurance, Unemployment Insurance and retirement insurance.\n",
    "- <Other>\n",
    "\n",
    "Now, which of <Third-party>,<Health>,<Social-Security>,<Other> topics best fit the following tweet? Answer with only the previous options that is most accurate and nothing else. Just name one of them with no more explanation.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 97/97 [06:28<00:00,  4.00s/it]\n"
     ]
    }
   ],
   "source": [
    "from timeout import timeout\n",
    "import os\n",
    "import errno \n",
    "\n",
    "responses=[]\n",
    "chatbot = hugchat.ChatBot(cookie_path=\"cookies.json\") \n",
    "\n",
    "@timeout(30, os.strerror(errno.ETIMEDOUT))\n",
    "def hugging_chat(prompt, temperature=0.1):\n",
    "    return  chatbot.chat(prompt, temperature=temperature)\n",
    "\n",
    "for i,tweet in enumerate(tqdm(df_labeled['text'])):\n",
    "    for try_time in range(2):\n",
    "        \n",
    "        try:\n",
    "            tweet = re.sub(r\"http\\S+\", '', tweet.replace('\\n',' '))\n",
    "#             tweet = translator.translate(tweet, dest='en').text\n",
    "            prompt_text = q+\"\\nText:\\n\"+tweet\n",
    "            \n",
    "            response = hugging_chat(prompt_text)\n",
    "            responses.append(response)\n",
    "            time.sleep(2)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            time.sleep(5)\n",
    "            print(f'timeout in data[{i}]',e)\n",
    "            \n",
    "    else:\n",
    "        print(f'response-error in data[{i}]')\n",
    "        responses.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses2=responses\n",
    "for i in range(len(responses)):\n",
    "    for x in ['Social-Security','Third-party','Health','Other']:\n",
    "        if x in responses[i]:\n",
    "            responses2[i]=x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purity_score: 0.3402061855670103\n",
      "NMI: 0.03648357558668947\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         health       1.00      0.05      0.10        20\n",
      "          other       0.21      0.17      0.19        29\n",
      "social-security       0.00      0.00      0.00        31\n",
      "    third-party       0.18      0.76      0.29        17\n",
      "\n",
      "       accuracy                           0.20        97\n",
      "      macro avg       0.35      0.25      0.14        97\n",
      "   weighted avg       0.30      0.20      0.13        97\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/x/Documents/Metodata/Topic Modeling/tmvenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/x/Documents/Metodata/Topic Modeling/tmvenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/x/Documents/Metodata/Topic Modeling/tmvenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "res = [r.replace('.','').lower().replace('<','').replace('>','') for r in responses2]\n",
    "res\n",
    "    \n",
    "    \n",
    "df2 = pd.DataFrame(res)\n",
    "df2.columns=['predict_ChatGPT']\n",
    "df2['label']=df_labeled['label'].apply(lambda x:x.replace('stok','stock')).to_list()\n",
    "df2['text']=df_labeled['text'].to_list()                 \n",
    "\n",
    "\n",
    "dict_label_normlise = {'tamin':'social-security',\n",
    "                 'person':'third-party',\n",
    "                 'insurance':'other',\n",
    "                      'health':'health',\n",
    "                      '-':'-'}\n",
    "df2['label'] = df2['label'].apply(lambda x:dict_label_normlise[x])\n",
    "\n",
    "\n",
    "df2\n",
    "q_metrics(df2[df2.predict_ChatGPT!='-']['label'],df2[df2.predict_ChatGPT!='-']['predict_ChatGPT'])\n",
    "print(classification_report(df2[df2.predict_ChatGPT!='-']['label'],df2[df2.predict_ChatGPT!='-']['predict_ChatGPT']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purity_score: 0.5555555555555556\n",
      "NMI: 0.33698267016508365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    currency       0.69      0.91      0.78        22\n",
      "        good       0.41      0.25      0.31        28\n",
      "       other       0.34      0.52      0.41        29\n",
      "       stock       1.00      0.45      0.62        20\n",
      "\n",
      "    accuracy                           0.52        99\n",
      "   macro avg       0.61      0.53      0.53        99\n",
      "weighted avg       0.57      0.52      0.51        99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "res = [r[1:-1].lower() if r[0]=='<' else 'good' if r.lower()=='other' else r.lower() for r in responses]\n",
    "\n",
    "df2 = pd.DataFrame(res)\n",
    "df2.columns=['predict_ChatGPT']\n",
    "df2['label']=df_labeled['label'].apply(lambda x:x.replace('stok','stock')).to_list()[:100]\n",
    "df2['text']=df_labeled['text'].to_list()[:100]                 \n",
    "# df2 = pd.concat([df2,df_labeled[['label']].reset_index(drop=True)],axis=1)\n",
    "df2\n",
    "q_metrics(df2[df2.predict_ChatGPT!='-']['label'],df2[df2.predict_ChatGPT!='-']['predict_ChatGPT'])\n",
    "print(classification_report(df2[df2.predict_ChatGPT!='-']['label'],df2[df2.predict_ChatGPT!='-']['predict_ChatGPT']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_ChatGPT</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>رامین پرچمی: بخاطر ۱۳۰ میلیون تومان بدهی ۳ سال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>currency</td>\n",
       "      <td>other</td>\n",
       "      <td>استعفا در سکوت/ کناره‌گیری #محمدرضا_عارف از ری...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>other</td>\n",
       "      <td>stock</td>\n",
       "      <td>بورس کالا دلیل افزایش ۲۰ درصدی قیمت آهن؟\\nبه گ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>currency</td>\n",
       "      <td>currency</td>\n",
       "      <td>جالب است که دلار در مسیر کانال 30 هزار تومانی ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>currency</td>\n",
       "      <td>currency</td>\n",
       "      <td>ادعای فارین پالیسی درباره استفاده ایران از ارز...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>other</td>\n",
       "      <td>good</td>\n",
       "      <td>فرمانده دریابانی #بوشهر از کشف بیش از 15 هزار ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>stock</td>\n",
       "      <td>good</td>\n",
       "      <td>عضو کمیسیون اقتصادی: مجلس با مسببین گرانی خودر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>currency</td>\n",
       "      <td>other</td>\n",
       "      <td>‼️اظهارات تحقیر آمیز ترامپ خطاب به کشورهای عرب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>نخست وزیر اسراییل همزمان با مذاکرات وین: \\n\\nط...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>تعرفه‌های پزشکی ۹۸ تصویب شد\\n\\nدبیر شورای عالی...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   predict_ChatGPT     label   \n",
       "0            other     other  \\\n",
       "1         currency     other   \n",
       "2            other     stock   \n",
       "3         currency  currency   \n",
       "4         currency  currency   \n",
       "..             ...       ...   \n",
       "95           other      good   \n",
       "96           stock      good   \n",
       "97        currency     other   \n",
       "98           other     other   \n",
       "99           other     other   \n",
       "\n",
       "                                                 text  \n",
       "0   رامین پرچمی: بخاطر ۱۳۰ میلیون تومان بدهی ۳ سال...  \n",
       "1   استعفا در سکوت/ کناره‌گیری #محمدرضا_عارف از ری...  \n",
       "2   بورس کالا دلیل افزایش ۲۰ درصدی قیمت آهن؟\\nبه گ...  \n",
       "3   جالب است که دلار در مسیر کانال 30 هزار تومانی ...  \n",
       "4   ادعای فارین پالیسی درباره استفاده ایران از ارز...  \n",
       "..                                                ...  \n",
       "95  فرمانده دریابانی #بوشهر از کشف بیش از 15 هزار ...  \n",
       "96  عضو کمیسیون اقتصادی: مجلس با مسببین گرانی خودر...  \n",
       "97  ‼️اظهارات تحقیر آمیز ترامپ خطاب به کشورهای عرب...  \n",
       "98  نخست وزیر اسراییل همزمان با مذاکرات وین: \\n\\nط...  \n",
       "99  تعرفه‌های پزشکی ۹۸ تصویب شد\\n\\nدبیر شورای عالی...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.to_csv(f'{path}/predict_HugChat-insurance-with_gtrans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'film': 40, 'art': 16, 'poet': 33, '-': 2})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df2.predict_ChatGPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "res2=[]\n",
    "for i,r in enumerate(responses):\n",
    "    try:\n",
    "        r=r.rstrip()\n",
    "        res2.append((ast.literal_eval( r[r.find('{'): r.rfind('}')+1].replace('topic','Topic')))\\\n",
    "                                     ['Topic']\\\n",
    "                    .lower().replace('\\\"','').replace('}',''))\n",
    "\n",
    "    except:\n",
    "        try:\n",
    "            res2.append((r.replace('Topic\": ','Topic: ').split('Topic: ')[-1].split()[0]).lower().replace('\\\"','').replace('}',''))\n",
    "#             res2.append(ast.literal_eval(r.replace('topic','Topic').replace(\"': '\",'\":\"').replace(\"{'\",'{\"').replace(\"'}\",'\"}').replace(\"\\',\\n \\'\",'\\\",\\n \\\"').split('}')[0]+'}'))\n",
    "        except:\n",
    "            res2.append('')\n",
    "            print(i)\n",
    "\n",
    "#     if res2[-1] in ['legal','news','traffic','gun','legal/crime','protests','revolution','human','crisis','family','prisoners','real','diplomacy','politics','humanrightsviolations','international','history','political','conspiracy' ,'prison','poverty']:\n",
    "#         res2[-1]='social'\n",
    "    if res2[-1] in ['coronavirus','health.','science','coronavirus']:\n",
    "        res2[-1] = 'health'\n",
    "    if res2[-1] in ['exchange' ,'currency' ,'economics.' ,'economy','signal']:\n",
    "        res2[-1]='economics'\n",
    "    if res2[-1] in ['entertainment','literature','tv','film.','filmfajr','legal/family','film/art','film','theater','music','cinema']:\n",
    "        res2[-1]='art'\n",
    "    if res2[-1] in ['sports','football', '#استقلال']:\n",
    "        res2[-1]='sport'\n",
    "    if res2[-1] in ['cars','transportation','religion','history']:\n",
    "        res2[-1]='social'\n",
    "    if res2[-1] in ['politics.']:\n",
    "        res2[-1]='politics'\n",
    "#     if res2[-1]in ['poetry','poet']:\n",
    "#         res2[-1]='poem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Topic: Economics': 17,\n",
       "         'Topic: Politics': 61,\n",
       "         'Topic: politics': 17,\n",
       "         'Topic: Health': 17,\n",
       "         'Topic: art': 2,\n",
       "         'Topic: Art': 7,\n",
       "         'Topic: sports': 17,\n",
       "         'Topic: Economics.': 1,\n",
       "         'Topic: sport': 1,\n",
       "         'Topic: Sport': 1,\n",
       "         'Topic: Social': 2,\n",
       "         'Topic: history': 1,\n",
       "         'Topic: Entertainment (Option: Art)': 1,\n",
       "         'Topic: Entertainment': 1})"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_HugChat</th>\n",
       "      <th>label</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>economics</td>\n",
       "      <td>economics</td>\n",
       "      <td>Topic: Economics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politics</td>\n",
       "      <td>sport</td>\n",
       "      <td>Topic: Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>economics</td>\n",
       "      <td>economics</td>\n",
       "      <td>Topic: Economics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>economics</td>\n",
       "      <td>economics</td>\n",
       "      <td>Topic: Economics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>politics</td>\n",
       "      <td>art</td>\n",
       "      <td>Topic: politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>art</td>\n",
       "      <td>art</td>\n",
       "      <td>Topic: Art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>art</td>\n",
       "      <td>art</td>\n",
       "      <td>Topic: art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>politics</td>\n",
       "      <td>art</td>\n",
       "      <td>Topic: Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>art</td>\n",
       "      <td>art</td>\n",
       "      <td>Topic: Art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>art</td>\n",
       "      <td>art</td>\n",
       "      <td>Topic: Art</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    predict_HugChat      label         responses\n",
       "0         economics  economics  Topic: Economics\n",
       "1          politics      sport   Topic: Politics\n",
       "2         economics  economics  Topic: Economics\n",
       "3         economics  economics  Topic: Economics\n",
       "4          politics        art   Topic: politics\n",
       "..              ...        ...               ...\n",
       "141             art        art        Topic: Art\n",
       "142             art        art        Topic: art\n",
       "143        politics        art   Topic: Politics\n",
       "144             art        art        Topic: Art\n",
       "145             art        art        Topic: Art\n",
       "\n",
       "[146 rows x 3 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(res2).rename(columns={'Topic':'predict_HugChat'})\n",
    "df2.columns=['predict_HugChat']\n",
    "df2 = pd.concat([df2,df_labeled[['label']]],axis=1)\n",
    "\n",
    "df2.dropna(inplace=True)\n",
    "df2['responses']=responses\n",
    "df2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'economics': 18,\n",
       "         'politics': 78,\n",
       "         'health': 17,\n",
       "         'art': 11,\n",
       "         'sport': 19,\n",
       "         'social': 3})"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['predict_HugChat'] = df2['predict_HugChat'].apply(lambda x: x.replace('health.','health'))\n",
    "Counter(df2['predict_HugChat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(f'{path}/predict_chathugging-media-en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(f'{path}/predict_ChatGPTchathugging-people-fa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purity_score: 0.9254658385093167\n",
      "NMI: 0.8417225303570115\n"
     ]
    }
   ],
   "source": [
    "q_metrics(df2['label'],df2['predict_ChatGPT'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmvenv",
   "language": "python",
   "name": "tmvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "365536dcbde60510dc9073d6b991cd35db2d9bac356a11f5b64279a5e6708b97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
