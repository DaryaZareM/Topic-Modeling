{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to format inputs to ChatGPT models\n",
    "\n",
    "ChatGPT is powered by `gpt-3.5-turbo` and `gpt-4`, OpenAI's most advanced models.\n",
    "\n",
    "You can build your own applications with `gpt-3.5-turbo` or `gpt-4` using the OpenAI API.\n",
    "\n",
    "Chat models take a series of messages as input, and return an AI-written message as output.\n",
    "\n",
    "This guide illustrates the chat format with a few example API calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the openai library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if needed, install and/or upgrade to the latest version of the OpenAI Python library\n",
    "\n",
    "# %pip install --upgrade openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the OpenAI Python library for calling the OpenAI API\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. An example chat API call\n",
    "\n",
    "A chat API call has two required inputs:\n",
    "- `model`: the name of the model you want to use (e.g., `gpt-3.5-turbo`, `gpt-4`, `gpt-4-0314`)\n",
    "- `messages`: a list of message objects, where each object has two required fields:\n",
    "    - `role`: the role of the messenger (either `system`, `user`, or `assistant`)\n",
    "    - `content`: the content of the message (e.g., `Write me a beautiful poem`)\n",
    "\n",
    "Messages can also contain an optional `name` field, which give the messenger a name. E.g., `example-user`, `Alice`, `BlackbeardBot`. Names may not contain spaces.\n",
    "\n",
    "Typically, a conversation will start with a system message that tells the assistant how to behave, followed by alternating user and assistant messages, but you are not required to follow this format.\n",
    "\n",
    "Let's look at an example chat API calls to see how the chat format works in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data labels: Counter({'tamin': 31, 'insurance': 29, 'health': 20, 'person': 17})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nb/d3bw47gn6qj6n_bg2n_g5y140000gn/T/ipykernel_3363/14004813.py:1: DtypeWarning: Columns (61,64,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_labeled = pd.read_csv(f'{path}insurance_dataset.csv')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_labeled = pd.read_csv(f'{path}insurance_dataset.csv')\n",
    "df_labeled = df_labeled[df_labeled['div']=='test'].reset_index(drop=True)\n",
    "df_labeled['label']=df_labeled['label'].apply(lambda x:x.replace('stok','stock'))\n",
    "print('Test data labels:',Counter(df_labeled.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "def q_metrics(y_true, y_pred,my_model=None):\n",
    "    contigency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    purity = np.sum(np.amax(contigency_matrix, axis=0)) / np.sum(contigency_matrix)\n",
    "  \n",
    "    print('purity_score:',purity)\n",
    "    print('NMI:',metrics.normalized_mutual_info_score(y_true, y_pred))\n",
    "    \n",
    "    if my_model!=None:\n",
    "        cm = CoherenceModel(model=my_model, corpus=bow_corpus, dictionary=dictionary, coherence='u_mass')\n",
    "        print('Coherence:',cm.get_coherence())\n",
    "\n",
    "def print_result(resres,my_model=None):\n",
    "    pred = []\n",
    "    for i in range(len(resres)):\n",
    "        pred.append(np.argmax(resres[i]))\n",
    "  \n",
    "    y_true = df[df['div']=='test']['topic']\n",
    "    y_pred = pred\n",
    "    q_metrics(y_true, y_pred,my_model)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_labeled['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install googletrans==3.1.0a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''this text is about insurance in  Iran.\n",
    "The text is about which of these topics?\n",
    "\n",
    "-<Third-party>: Third-party insurance is a type of insurance It is often mandatory for certain types of insurance, like car insurance, and is generally less expensive than comprehensive coverage. In Iran we are forced to get Third-party insurance for cars, and if we say insurance for cars without specification means Third-party insurance.\n",
    "-<Health>: Health insurance taken out to cover the cost of medical care, doctor costs, medicine, hospital and ….\n",
    "- <Social-Security>: Social-Security that is about Social Security organisation and also Life insurance, Unemployment Insurance and retirement insurance.\n",
    "- <Other>\n",
    "\n",
    "Now, which of <Third-party>,<Health>,<Social-Security>,<Other> topics best fit the following tweet? Answer with only the previous options that is most accurate and nothing else. Just name one of them with no more explanation.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "output = 'output is only one word <stok> or <currency> or <good> or <other>'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example OpenAI Python library request\n",
    "# \"firs translate this tweet from fa to en then say it's topic is economics or sport or art or health or social or politic.\"+\"\\ntweet:\\n\"+tweet+output_format\n",
    "# q+toppics+\"\\ntweet:\\n\"+tweet+output_format\n",
    "\n",
    "responses=[] \n",
    "for tweet in tqdm(df_labeled['text']):\n",
    "    \n",
    "    openai.api_key = 'YOUR_API_KEY'\n",
    "    MODEL = \"gpt-3.5-turbo\"\n",
    "    tweet = re.sub(r\"http\\S+\", '', tweet.replace('\\n',' '))\n",
    "#     tweet = translator.translate(tweet, dest='en').text\n",
    "#     prompt_text=q+toppics+\"\\ntweet:\\n\"+tweet+output_format\n",
    "#     prompt_text = \"firs translate this tweet from fa to en then say it's topic is economics or sport or art or health or social or politic.\"+\"\\ntweet:\\n\"+tweet+output_format\n",
    "    prompt_text = q+\"\\nText:\\n\"+tweet\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a classifier that tag persian texts your output is only one word <stok> or <currency> or <good> or <other>\"},\n",
    "            {\"role\": \"user\", \"content\":prompt_text},\n",
    "\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    responses.append(response.choices[0].message.content)\n",
    "    time.sleep(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_label = lambda x:x.lower().replace(' ','').replace('<','').replace('>','')\n",
    "responses = list(map(norm_label,responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purity_score: 0.6597938144329897\n",
      "NMI: 0.44193190397109255\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         health       0.60      0.60      0.60        20\n",
      "      insurance       0.00      0.00      0.00        29\n",
      "          other       0.00      0.00      0.00         0\n",
      "         person       0.00      0.00      0.00        17\n",
      "social-security       0.00      0.00      0.00         0\n",
      "          tamin       0.00      0.00      0.00        31\n",
      "    third-party       0.00      0.00      0.00         0\n",
      "\n",
      "       accuracy                           0.12        97\n",
      "      macro avg       0.09      0.09      0.09        97\n",
      "   weighted avg       0.12      0.12      0.12        97\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/x/Documents/Metodata/Topic Modeling/tmvenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/x/Documents/Metodata/Topic Modeling/tmvenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/x/Documents/Metodata/Topic Modeling/tmvenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/x/Documents/Metodata/Topic Modeling/tmvenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/x/Documents/Metodata/Topic Modeling/tmvenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/x/Documents/Metodata/Topic Modeling/tmvenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# res = [r[1:-1] for r in responses]\n",
    "res = responses\n",
    "df2 = pd.DataFrame(res)\n",
    "df2.columns=['predict_ChatGPT']\n",
    "df2['label']=df_labeled['label'].to_list()[:100]\n",
    "df2['text']=df_labeled['text'].to_list()[:100]                    \n",
    "# df2 = pd.concat([df2,df_labeled[['label']].reset_index(drop=True)],axis=1)\n",
    "df2\n",
    "q_metrics(df2['label'],df2['predict_ChatGPT'])\n",
    "print(classification_report(df2['label'],df2['predict_ChatGPT']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_ChatGPT</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>رامین پرچمی: بخاطر ۱۳۰ میلیون تومان بدهی ۳ سال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>استعفا در سکوت/ کناره‌گیری #محمدرضا_عارف از ری...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good</td>\n",
       "      <td>stock</td>\n",
       "      <td>بورس کالا دلیل افزایش ۲۰ درصدی قیمت آهن؟\\nبه گ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>currency</td>\n",
       "      <td>currency</td>\n",
       "      <td>جالب است که دلار در مسیر کانال 30 هزار تومانی ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>currency</td>\n",
       "      <td>currency</td>\n",
       "      <td>ادعای فارین پالیسی درباره استفاده ایران از ارز...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>فرمانده دریابانی #بوشهر از کشف بیش از 15 هزار ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>عضو کمیسیون اقتصادی: مجلس با مسببین گرانی خودر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>‼️اظهارات تحقیر آمیز ترامپ خطاب به کشورهای عرب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>نخست وزیر اسراییل همزمان با مذاکرات وین: \\n\\nط...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>good</td>\n",
       "      <td>other</td>\n",
       "      <td>تعرفه‌های پزشکی ۹۸ تصویب شد\\n\\nدبیر شورای عالی...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   predict_ChatGPT     label   \n",
       "0            other     other  \\\n",
       "1            other     other   \n",
       "2             good     stock   \n",
       "3         currency  currency   \n",
       "4         currency  currency   \n",
       "..             ...       ...   \n",
       "95            good      good   \n",
       "96            good      good   \n",
       "97           other     other   \n",
       "98           other     other   \n",
       "99            good     other   \n",
       "\n",
       "                                                 text  \n",
       "0   رامین پرچمی: بخاطر ۱۳۰ میلیون تومان بدهی ۳ سال...  \n",
       "1   استعفا در سکوت/ کناره‌گیری #محمدرضا_عارف از ری...  \n",
       "2   بورس کالا دلیل افزایش ۲۰ درصدی قیمت آهن؟\\nبه گ...  \n",
       "3   جالب است که دلار در مسیر کانال 30 هزار تومانی ...  \n",
       "4   ادعای فارین پالیسی درباره استفاده ایران از ارز...  \n",
       "..                                                ...  \n",
       "95  فرمانده دریابانی #بوشهر از کشف بیش از 15 هزار ...  \n",
       "96  عضو کمیسیون اقتصادی: مجلس با مسببین گرانی خودر...  \n",
       "97  ‼️اظهارات تحقیر آمیز ترامپ خطاب به کشورهای عرب...  \n",
       "98  نخست وزیر اسراییل همزمان با مذاکرات وین: \\n\\nط...  \n",
       "99  تعرفه‌های پزشکی ۹۸ تصویب شد\\n\\nدبیر شورای عالی...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(f'{path}/predict_ChatGPT-economics-gtrans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "res2=[]\n",
    "for i,r in enumerate(responses):\n",
    "    try:\n",
    "        res2.append((ast.literal_eval(\"{\"+re.search('{(.*)}', r).group(1)+\"}\")['Topic']).lower().replace('\\\"','').replace('}',''))\n",
    "        \n",
    "    except:\n",
    "        try:\n",
    "            \n",
    "            res2.append((r.replace('Topic\": ','Topic: ').split('Topic: ')[-1].split()[0]).lower().replace('\\\"','').replace('}',''))\n",
    "#             res2.append(ast.literal_eval(r.replace('topic','Topic').replace(\"': '\",'\":\"').replace(\"{'\",'{\"').replace(\"'}\",'\"}').replace(\"\\',\\n \\'\",'\\\",\\n \\\"').split('}')[0]+'}'))\n",
    "        except:\n",
    "            print(i)\n",
    "    if res2[-1]=='politics':\n",
    "        res2[-1]='social'\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_ChatGPT</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>social</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sport</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poem</td>\n",
       "      <td>poem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>health</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>social</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>politics</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>health</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>sport</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>health</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>art</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    predict_ChatGPT   label\n",
       "0            social  social\n",
       "1             sport   sport\n",
       "2              poem    poem\n",
       "3            health  social\n",
       "4            social  social\n",
       "..              ...     ...\n",
       "156        politics  social\n",
       "157          health  health\n",
       "158           sport  health\n",
       "159          health  health\n",
       "160             art     art\n",
       "\n",
       "[161 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(res2).rename(columns={'Topic':'predict_ChatGPT'})\n",
    "df2.columns=['predict_ChatGPT']\n",
    "df2 = pd.concat([df2,df_labeled[['label']]],axis=1)\n",
    "df2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'social': 28,\n",
       "         'sport': 31,\n",
       "         'poem': 23,\n",
       "         'health': 44,\n",
       "         'economics': 22,\n",
       "         'art': 13})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df2['predict_ChatGPT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(f'{path}/predict_ChatGPT-people-fa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purity_score: 0.9254658385093167\n",
      "NMI: 0.8417225303570115\n"
     ]
    }
   ],
   "source": [
    "q_metrics(df2['label'],df2['predict_ChatGPT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nb/d3bw47gn6qj6n_bg2n_g5y140000gn/T/ipykernel_3384/1143293337.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_labeled = pd.read_csv(f'{path}art_dataset-stm_pred.csv')\n"
     ]
    }
   ],
   "source": [
    "df_labeled = pd.read_csv(f'{path}art_dataset-stm_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_labeled['stm_pred'] = df_labeled[['pred.1','pred.2','pred.3']]. idxmax(axis=1)\n",
    "df_labeled['stm_pred'] = df_labeled['stm_pred'].apply(lambda x:int(x[-1])-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purity_score: 0.8461538461538461\n",
      "NMI: 0.6265048896128346\n"
     ]
    }
   ],
   "source": [
    "q_metrics(df_labeled[df_labeled['div']=='test']['label'],df_labeled[df_labeled['div']=='test']['stm_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         art       0.22      0.14      0.17        14\n",
      "        film       0.78      0.83      0.80        42\n",
      "        poet       0.95      1.00      0.97        35\n",
      "\n",
      "    accuracy                           0.79        91\n",
      "   macro avg       0.65      0.66      0.65        91\n",
      "weighted avg       0.76      0.79      0.77        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "topic_name={1:'film',0:'art',2:'poet'}\n",
    "y_pred = [*map(topic_name.get, list(df_labeled[df_labeled['div']=='test']['stm_pred']))]\n",
    "print(classification_report(df_labeled[df_labeled['div']=='test']['label'].to_list(),y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmvenv",
   "language": "python",
   "name": "tmvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "365536dcbde60510dc9073d6b991cd35db2d9bac356a11f5b64279a5e6708b97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
